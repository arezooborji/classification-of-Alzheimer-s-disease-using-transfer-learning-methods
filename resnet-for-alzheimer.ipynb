{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#written by Arezoo Borji\n",
        "# import numpy as np\n",
        "# import pandas as pd\n",
        "# import os\n",
        "# for dirname, _, filenames in os.walk('/content/drive/MyDrive/alzheimer_Dataset1'):\n",
        "#     for filename in filenames[0:1000]:\n",
        "#         print(os.path.join(dirname, filename))"
      ],
      "metadata": {
        "id": "Iu6Foe-_iirv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import datetime\n",
        "import random\n",
        "import nibabel as nib\n",
        "import glob\n",
        "import os\n",
        "\n",
        "# from sklearn.metrics import accuracy_score,f1_score,precision_score,recall_score,roc_curve,auc\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras import layers,optimizers\n",
        "import cv2\n",
        "import imageio\n",
        "import wandb\n",
        "from wandb.keras import WandbCallback"
      ],
      "metadata": {
        "id": "wzmUyxxpii2z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.init(project=\"1newkfoldtransferlearningADvsCN2\")\n",
        "\n",
        "config = wandb.config\n",
        "config.learning_rate = 0.001"
      ],
      "metadata": {
        "id": "LkE9LyK_ii54"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_path = '/content/drive/MyDrive/'\n",
        "width = height = 224\n",
        "batch_size = 64\n",
        "data_generator = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    horizontal_flip = False,\n",
        "    # zoom_range = 0.1,\n",
        "    validation_split = 0.15\n"
      ],
      "metadata": {
        "id": "Ddjd-nspii9R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = data_generator.flow_from_directory(\n",
        "    os.path.join(dataset_path,'alzheimer_dataset1'),\n",
        "    target_size = (width,height),\n",
        "    class_mode = 'categorical',\n",
        "    batch_size = batch_size,\n",
        "    shuffle = False,\n",
        "    subset= 'training'"
      ],
      "metadata": {
        "id": "CwTTmCVWijAP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "RYX2a3VAijDn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_data = data_generator.flow_from_directory(\n",
        "    os.path.join(dataset_path,'alzheimer_dataset1'),\n",
        "    target_size = (width,height),\n",
        "    class_mode = 'categorical',\n",
        "    batch_size = batch_size,\n",
        "    shuffle = False,\n",
        "    subset= 'validation'\n",
        ")"
      ],
      "metadata": {
        "id": "g5mcrCyjijHE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_data = data_generator.flow_from_directory(\n",
        "    os.path.join(dataset_path,'/content/drive/MyDrive/test1'),\n",
        "    target_size = (width,height),\n",
        "    class_mode = 'categorical',\n",
        "    batch_size = batch_size,\n",
        "    shuffle = False,\n",
        ")"
      ],
      "metadata": {
        "id": "e1GH7xWCkYce"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_model = tf.keras.applications.ResNet50V2(\n",
        "    input_shape = (width,height,3),\n",
        "    include_top = False,\n",
        "    weights = 'imagenet',\n",
        "    pooling = 'max'\n",
        ")"
      ],
      "metadata": {
        "id": "F7bJewiVkcAK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for layer in base_model.layers[:-8]:\n",
        "  layer.trainable = False"
      ],
      "metadata": {
        "id": "O9U_3iFzkgUg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_images = next(train_data)[0]\n",
        "plt.figure(figsize=(8,8))\n",
        "\n",
        "for i in range(16):\n",
        "  plt.subplot(4,4,i+1)\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])\n",
        "  plt.grid(False)\n",
        "  plt.imshow(train_images[i],cmap=plt.cm.binary)"
      ],
      "metadata": {
        "id": "TCwF5zEPlDj_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from keras import layers\n",
        "from keras import models\n",
        "import tensorflow as tf\n",
        "from keras.layers import Dropout\n",
        "layers=[\n",
        "\n",
        "    # tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(224, 224, 3)),\n",
        "    # tf.keras.layers.MaxPooling2D(2,2),\n",
        "\n",
        "    # tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "    # tf.keras.layers.MaxPooling2D(2,2),\n",
        "\n",
        "    # tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
        "    # tf.keras.layers.MaxPooling2D(2,2),\n",
        "    # tf.keras.layers.Dropout(0.4),\n",
        "\n",
        "    # tf.keras.layers.Flatten(),\n",
        "\n",
        "     # 512 neuron hidden layer\n",
        "     base_model,\n",
        "    tf.keras.layers.Dense(512, activation=\"relu\"),\n",
        "    tf.keras.layers.Dense(2, activation=\"sigmoid\")\n",
        "\n",
        "]"
      ],
      "metadata": {
        "id": "5xvAMdw6lHg1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model=tf.keras.Sequential(layers)\n",
        "model.compile(optimizers.Adam(learning_rate=config.learning_rate),\n",
        "             loss='binary_crossentropy',\n",
        "             metrics = ['accuracy'] )"
      ],
      "metadata": {
        "id": "MJF06kpvl3EO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "hrzjCLIfmDjR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(train_data,\n",
        "                              validation_data=val_data,\n",
        "                              epochs=10,\n",
        "                    callbacks = [WandbCallback()])"
      ],
      "metadata": {
        "id": "ti6P4KKnmDm4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        " accuracy = history.history['accuracy']\n",
        " val_accuracy = history.history['val_accuracy']\n",
        " loss = history.history['loss']\n",
        " val_loss = history.history['val_loss']\n",
        " epochs = range(len(accuracy))\n",
        " plt.plot(epochs, accuracy, 'r', label=\"Training accuracy\")\n",
        " plt.plot(epochs, val_accuracy, 'b', label=\"Validation accuracy\")\n",
        " plt.title(\"Training and test accuracy\")\n",
        " plt.legend()\n",
        " plt.figure()\n",
        " plt.plot(epochs, loss, 'r', label=\"Training loss\")\n",
        " plt.plot(epochs, val_loss, 'b', label=\"Training Validation_loss\")\n",
        " plt.title(\"Training and test loss\")\n",
        " plt.legend()\n",
        " plt.figure()"
      ],
      "metadata": {
        "id": "okNYavpRmDuL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "Y_pred = model.predict(test_data)\n",
        "y_pred = np.argmax(Y_pred, axis = 1)\n",
        "print('confusion Matrix')\n",
        "print(confusion_matrix(test_data.classes, y_pred))\n",
        "\n",
        "target_names = list(test_data.class_indices.keys())\n",
        "print('Classification Report')\n",
        "print(classification_report(test_data.classes, y_pred, target_names=target_names))"
      ],
      "metadata": {
        "id": "h3ecn0BKmMkw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split,KFold,cross_val_score\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Activation, Dense,Flatten,LSTM,Dropout\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "# Define per-fold score containers <-- these are new\n",
        "acc_per_fold = []\n",
        "loss_per_fold = []\n",
        "\n",
        "\n",
        "# Merge inputs and targets\n",
        "inputs = np.concatenate((val_data,test_data),axis=0)\n",
        "targets = np.concatenate((val_data,test_data),axis=0)\n",
        "\n",
        "# Define the K-fold Cross Validator\n",
        "kfold = KFold(5, shuffle=True)\n",
        "\n",
        "# K-fold Cross Validation model evaluation\n",
        "fold_no = 1\n",
        "for train, test in kfold.split(inputs, targets):\n",
        "  # create and fit resnet\n",
        "  model = Sequential()\n",
        "  layers=[base_model,\n",
        "      tf.keras.layers.Dense(512, activation=\"relu\"),\n",
        "      tf.keras.layers.Dense(2, activation=\"sigmoid\")\n",
        "  ]\n",
        "  model.compile(optimizers.Adam(learning_rate=config.learning_rate),\n",
        "             loss='binary_crossentropy',\n",
        "             metrics = ['accuracy'] )\n",
        "\n",
        "  # Generate a print\n",
        "  print('------------------------------------------------------------------------')\n",
        "  print(f'Training for fold {fold_no} ...')\n",
        "  # Fit data to model\n",
        "  history = model.fit(train_data,\n",
        "                      validation_data=val_data,\n",
        "                      epochs=8,\n",
        "                      callbacks = [WandbCallback()])\n",
        "\n",
        "  # Generate generalization metrics\n",
        "  scores = model.evaluate(inputs[test], targets[test], verbose=0)\n",
        "  print(f'Score for fold {fold_no}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}%')\n",
        "  acc_per_fold.append(scores[1] * 100)\n",
        "  loss_per_fold.append(scores[0])\n",
        "\n",
        "  # Increase fold number\n",
        "  fold_no = fold_no + 1"
      ],
      "metadata": {
        "id": "w41pfEGXmMoH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JCgK0dYymMrj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ng06XXYOmMuP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "66AbL6czmMxP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}